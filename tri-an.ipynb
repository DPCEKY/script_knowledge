{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 60\n",
    "batch_size_train = 5\n",
    "batch_size_eval = 256\n",
    "embed_dim = 300\n",
    "# embed_from = \"glove.840B.300d\"\n",
    "hidden_size = 96\n",
    "num_layers = 1\n",
    "rnn_dropout_rate = 0\n",
    "embed_dropout_rate = 0.4\n",
    "rnn_output_dropout_rate = 0.4\n",
    "grad_clipping = 10\n",
    "lr = 2e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "refer to \n",
    "\n",
    "http://anie.me/On-Torchtext/\n",
    "\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "http://mlexplained.com/2018/02/15/language-modeling-tutorial-in-torchtext-practical-torchtext-part-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'preprocessed'\n",
    "combined_fname = 'all-combined-data-processed.json'\n",
    "train_fname = 'train-trial-combined-data-processed.json'\n",
    "dev_fname = 'dev-data-processed.json'\n",
    "test_fname = 'test-data-processed.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have keys: 'id', 'd_words', 'd_pos', 'd_ner', 'q_words', 'q_pos', 'c_words', 'label', 'in_q', 'in_c', 'lemma_in_q', 'tf', 'p_q_relation', 'p_c_relation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(tf_batch, tf_lens):\n",
    "    \n",
    "    for i in range(len(tf_batch)):\n",
    "        for j in range(len(tf_batch[0])):\n",
    "            if tf_batch[i][j] == '<pad>':\n",
    "                tf_batch[i][j] = 0\n",
    "            else:\n",
    "                tf_batch[i][j] = float(tf_batch[i][j])\n",
    "    print(tf_batch)\n",
    "    return tf_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 20482, val: 2822, test: 5594\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split(\" \")\n",
    "\n",
    "TEXT = data.ReversibleField(sequential=True, tokenize=tokenizer, lower=False, include_lengths=True)\n",
    "POS = data.ReversibleField(sequential=True, lower=False, include_lengths=True)\n",
    "NER = data.ReversibleField(sequential=True, lower=False, include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "# IN_Q = data.Field(sequential=True, use_vocab=False, include_lengths=True, postprocessing=lambda arr, _: [print('!!!', len(x)) for x in arr])\n",
    "# IN_C = data.Field(sequential=True, use_vocab=False, include_lengths=True)\n",
    "# LEMMA_IN_Q = data.Field(sequential=True, use_vocab=False, include_lengths=True)\n",
    "# LEMMA_IN_C = data.Field(sequential=True, use_vocab=False, include_lengths=True)\n",
    "TF = data.Field(sequential=True, use_vocab=False, include_lengths=True, postprocessing=to_numeric)\n",
    "\n",
    "train, val, test = data.TabularDataset.splits(\n",
    "    path=data_dir, train=train_fname,\n",
    "    validation=dev_fname, test=test_fname, format='json',\n",
    "    fields={'d_words': ('d_words', TEXT),\n",
    "            'd_pos':   ('d_pos', POS),\n",
    "            'd_ner':   ('d_ner', NER),\n",
    "            'q_words': ('q_words', TEXT),\n",
    "            'q_pos':   ('q_pos', POS),\n",
    "            'c_words': ('c_words', TEXT),\n",
    "            'label': ('label', LABEL),\n",
    "#             'in_q': ('in_q', IN_Q),\n",
    "#             'in_c': ('in_c', IN_C),\n",
    "#             'lemma_in_q': ('lemma_in_q', LEMMA_IN_Q),\n",
    "#             'lemma_in_c': ('lemma_in_c', LEMMA_IN_C),\n",
    "            'tf': ('tf', TF)\n",
    "           })\n",
    "\n",
    "print('train: %d, val: %d, test: %d' % (len(train), len(val), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 12718\n",
      "pos size: 51\n",
      "ner size: 21\n"
     ]
    }
   ],
   "source": [
    "# combined is only used for building vocabulary\n",
    "combined = data.TabularDataset(\n",
    "    path=os.path.join(data_dir, combined_fname), format='json',\n",
    "    fields={'d_words': ('d_words', TEXT),\n",
    "            'd_pos':   ('d_pos', POS),\n",
    "            'd_ner':   ('d_ner', NER),\n",
    "            'q_words': ('q_words', TEXT),\n",
    "            'q_pos':   ('q_pos', POS),\n",
    "            'c_words': ('c_words', TEXT),\n",
    "            'label': ('label', LABEL),\n",
    "#             'in_q': ('in_q', IN_Q),\n",
    "#             'in_c': ('in_c', IN_C),\n",
    "#             'lemma_in_q': ('lemma_in_q', LEMMA_IN_Q),\n",
    "#             'lemma_in_c': ('lemma_in_c', LEMMA_IN_C),\n",
    "            'tf': ('tf', TF)\n",
    "           })\n",
    "\n",
    "# specify the path to the localy saved vectors\n",
    "vec = torchtext.vocab.Vectors('glove.840B.300d.txt', data_dir)\n",
    "TEXT.build_vocab(combined, vectors=vec)\n",
    "POS.build_vocab(combined)\n",
    "NER.build_vocab(combined)\n",
    "\n",
    "print('vocab size: %d' % len(TEXT.vocab))\n",
    "print('pos size: %d' % len(POS.vocab))\n",
    "print('ner size: %d' % len(NER.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 4097, val batches: 12, test batches: 22\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = data.Iterator.splits(\n",
    "        (train, val, test), batch_sizes=(batch_size_train, batch_size_eval, batch_size_eval), \\\n",
    "    sort_key=lambda x: len(x.d_words), device=device, sort_within_batch=False, repeat=False)\n",
    "\n",
    "print('train batches: %d, val batches: %d, test batches: %d' % (len(train_iter), \\\n",
    "                                                                len(val_iter), len(test_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.57, 1.68, 1.3, 1.05, 1.02, 1.79, 1.37, 1.52, 1.43, 1.04, 1.78, 1.68, 1.3, 0.97, 1.68, 1.43, 1.1, 1.5, 1.57, 1.06, 1.43, 1.46, 1.81, 1.88, 0.77, 0.23, 1.29, 1.57, 1.12, 1.57, 1.24, 1.77, 0.98, 1.43, 1.52, 0.23, 1.57, 1.31, 1.65, 1.43, 0.95, 0.23, 1.57, 0.99, 1.38, 1.78, 1.3, 0.23, 1.45, 1.68, 0.77, 0.23, 1.79, 1.02, 1.43, 1.48, 1.78, 1.43, 0.89, 0.23, 1.57, 1.45, 1.34, 1.43, 0.96, 0.23, 0.99, 1.52, 1.81, 1.43, 1.78, 1.3, 0.23, 1.79, 1.35, 1.43, 1.78, 1.68, 1.02, 0.99, 1.78, 1.43, 0.8, 0.8, 0.23, 1.57, 1.34, 1.52, 1.43, 0.84, 0.23, 0.99, 1.43, 1.78, 1.3, 0.23, 1.79, 1.25, 1.43, 1.52, 1.78, 1.68, 1.02, 0.99, 1.32, 1.77, 1.88, 0.96, 1.78, 1.43, 0.8, 0.8, 0.23, 0.92, 0.23, 1.57, 1.52, 1.77, 1.03, 1.52, 1.43, 1.04, 0.23, 1.52, 1.55, 1.52, 0.51, 1.3, 0.23, 1.79, 1.65, 1.34, 1.68, 1.39, 1.49, 1.77, 1.24, 1.43, 1.79, 1.3, 1.88, 1.2, 1.06, 1.3, 0.23, 1.49, 1.57, 1.38, 1.54, 1.11, 0.23, 1.57, 1.52, 1.77, 1.29, 1.42, 1.88, 0.97, 1.77, 1.33, 1.51, 1.16, 0.23, 1.49, 1.57, 1.39, 0.23, 1.57, 0.99, 1.88, 0.94, 1.3, 1.79, 1.25, 1.43, 0.82, 1.78, 1.43, 0.8, 0.8, 0.23, 1.42, 1.43, 1.1, 1.71, 1.02, 1.35, 0.23, 0, 0, 0, 0, 0, 0], [1.62, 1.2, 0.23, 1.43, 1.57, 1.68, 1.21, 1.14, 1.77, 1.09, 1.02, 1.62, 1.88, 1.05, 1.22, 0.23, 1.57, 1.19, 1.88, 0.55, 1.18, 0.23, 1.57, 0.23, 1.43, 1.14, 1.38, 1.47, 1.57, 1.41, 1.36, 1.48, 1.62, 1.88, 1.22, 0.23, 1.57, 1.0, 1.46, 1.81, 1.88, 1.05, 1.79, 1.35, 1.88, 0.82, 1.24, 1.88, 1.27, 1.16, 0.23, 1.57, 1.0, 1.48, 1.77, 1.88, 1.16, 1.79, 1.14, 1.42, 1.88, 0.64, 0.23, 1.47, 1.57, 1.41, 1.47, 1.52, 1.52, 0.79, 1.88, 0.55, 0.23, 1.57, 0.65, 1.49, 1.57, 1.25, 1.66, 1.65, 1.68, 1.43, 1.02, 0.23, 1.45, 0.23, 1.57, 1.21, 1.88, 1.36, 1.79, 1.19, 0.97, 1.77, 0.86, 1.88, 1.16, 0.23, 1.57, 0.96, 1.88, 0.23, 0.23, 1.79, 1.06, 1.88, 1.16, 1.33, 0.23, 1.57, 0.89, 1.43, 1.02, 1.65, 1.68, 1.3, 0.23, 1.09, 0.23, 0.23, 1.79, 1.0, 1.11, 1.47, 1.66, 1.48, 1.41, 1.15, 1.42, 1.88, 0.87, 0.23, 1.32, 1.43, 1.02, 1.68, 1.22, 1.88, 1.39, 0.23, 1.57, 1.31, 1.88, 1.27, 1.16, 1.25, 1.49, 1.79, 1.21, 1.88, 0.97, 1.78, 1.88, 1.14, 1.2, 1.77, 1.07, 1.88, 1.16, 1.35, 0.23, 1.57, 1.26, 1.43, 1.02, 1.68, 0.83, 0.23, 1.23, 1.49, 1.49, 1.48, 1.68, 0.95, 0.23, 1.79, 1.43, 1.0, 1.3, 1.24, 1.88, 1.05, 0.23, 1.43, 1.2, 1.35, 1.68, 1.02, 1.79, 1.52, 1.68, 1.15, 1.07, 0.23], [1.67, 1.88, 1.53, 1.81, 1.88, 1.24, 1.01, 1.37, 1.57, 1.34, 1.66, 1.65, 1.71, 1.3, 1.77, 1.61, 1.49, 1.77, 1.19, 1.88, 1.06, 0.23, 1.57, 1.55, 1.48, 1.06, 1.66, 1.57, 1.19, 1.3, 1.43, 1.44, 1.12, 1.09, 1.62, 1.43, 1.27, 1.26, 0.23, 1.33, 1.57, 1.44, 1.77, 1.47, 1.34, 1.24, 1.77, 1.61, 1.27, 1.52, 1.59, 1.53, 1.03, 0.23, 1.49, 1.65, 1.04, 1.62, 1.24, 1.77, 1.24, 1.45, 1.57, 1.3, 1.77, 1.47, 1.65, 0.23, 1.47, 1.57, 1.06, 1.35, 1.62, 1.43, 1.26, 1.65, 1.52, 1.81, 1.88, 1.06, 1.77, 1.19, 1.78, 1.27, 0.23, 1.57, 1.28, 1.68, 1.77, 1.39, 1.35, 1.79, 1.15, 1.43, 1.38, 0.23, 1.5, 1.57, 1.48, 1.62, 1.57, 1.5, 1.47, 1.43, 1.26, 1.79, 1.39, 1.38, 1.57, 0.86, 1.77, 1.88, 1.4, 0.23, 1.57, 1.15, 1.78, 1.43, 1.05, 1.38, 1.79, 1.1, 1.04, 0.23, 1.5, 1.62, 1.57, 1.27, 1.68, 1.77, 1.88, 1.32, 1.27, 1.39, 1.57, 1.55, 1.25, 1.04, 1.52, 1.81, 1.43, 1.06, 0.23, 1.57, 1.18, 1.88, 1.06, 1.66, 1.57, 1.55, 1.17, 1.79, 1.22, 1.35, 1.88, 1.31, 1.66, 1.57, 1.17, 1.43, 0.23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.42, 1.24, 1.77, 0.84, 1.48, 1.09, 1.68, 1.6, 1.23, 0.23, 1.62, 1.68, 1.3, 1.77, 1.38, 1.88, 1.4, 1.02, 1.68, 1.6, 1.07, 1.05, 1.62, 1.88, 1.38, 0.23, 1.62, 1.68, 1.3, 1.77, 1.38, 1.68, 1.36, 1.02, 1.79, 1.68, 1.15, 1.77, 1.55, 1.19, 1.44, 1.65, 0.23, 1.62, 1.14, 1.26, 1.68, 1.39, 1.77, 0.84, 1.09, 1.42, 1.62, 1.33, 1.24, 1.77, 1.48, 1.65, 1.42, 1.79, 1.62, 1.68, 1.15, 1.62, 1.68, 1.3, 1.77, 1.48, 1.65, 1.22, 0.23, 1.47, 1.62, 0.98, 1.39, 1.77, 0.84, 1.09, 1.68, 1.27, 1.79, 1.68, 1.04, 1.81, 1.35, 1.12, 1.31, 1.48, 1.47, 1.62, 1.43, 1.12, 1.88, 1.53, 1.54, 1.66, 0.83, 1.48, 1.68, 1.88, 1.44, 1.81, 1.35, 1.12, 0.23, 1.62, 1.02, 1.77, 1.21, 1.88, 1.04, 1.77, 0.84, 1.09, 1.79, 1.88, 1.09, 1.36, 1.77, 0.84, 1.65, 1.78, 1.68, 1.35, 1.01, 1.39, 1.65, 1.15, 1.77, 0.97, 1.56, 1.68, 1.18, 1.31, 1.09, 1.77, 1.21, 0.23, 1.62, 1.28, 1.77, 0.89, 1.88, 1.09, 1.39, 1.65, 0.23, 1.79, 1.45, 1.27, 1.65, 0.84, 1.68, 1.37, 1.5, 1.23, 1.79, 1.34, 1.65, 1.37, 1.88, 0.86, 1.79, 1.06, 1.65, 0.23, 1.62, 1.14, 0.9, 1.88, 1.09, 1.68, 1.6, 1.02, 1.79, 1.68, 1.02, 1.81, 1.29, 0.23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.43, 1.26, 1.79, 1.57, 1.21, 1.77, 1.17, 1.68, 1.27, 1.5, 1.05, 0.23, 1.55, 1.52, 1.68, 1.27, 1.38, 1.68, 1.33, 0.23, 1.43, 1.25, 1.77, 1.34, 1.79, 1.02, 1.68, 1.27, 0.23, 1.43, 1.04, 1.77, 1.68, 1.19, 1.19, 1.66, 1.52, 1.68, 1.27, 0.97, 1.23, 0.23, 1.43, 1.14, 1.42, 1.52, 1.81, 1.88, 1.15, 1.66, 1.55, 1.31, 0.23, 1.48, 1.81, 1.88, 1.15, 1.55, 1.06, 0.23, 1.48, 1.52, 1.68, 1.25, 1.81, 1.29, 0.23, 1.79, 1.48, 1.55, 0.9, 0.23, 1.43, 1.26, 1.79, 1.57, 1.24, 1.25, 1.66, 1.43, 1.21, 1.77, 1.17, 1.68, 1.2, 1.27, 0.23, 1.48, 1.25, 1.68, 1.27, 1.66, 1.52, 1.24, 1.51, 1.78, 1.88, 0.98, 0.23, 1.88, 1.19, 1.77, 1.02, 1.88, 1.27, 1.28, 1.68, 1.88, 1.18, 0.23, 1.57, 1.3, 1.43, 1.27, 1.19, 1.78, 1.88, 1.02, 1.79, 1.21, 1.43, 1.04, 1.4, 0.23, 1.88, 1.21, 1.29, 1.88, 1.38, 0.23, 1.45, 1.21, 1.41, 1.77, 1.2, 1.43, 1.19, 0.23, 1.57, 1.34, 1.43, 1.19, 1.79, 0.86, 0.23, 1.88, 1.27, 1.2, 1.31, 1.46, 1.81, 1.88, 1.21, 0.23, 1.43, 1.26, 1.1, 1.48, 1.88, 1.27, 1.62, 1.88, 1.21, 1.79, 1.43, 1.31, 1.37, 0.23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 5]\n",
      "\t[.d_words]:('[torch.LongTensor of size 194x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.d_pos]:('[torch.LongTensor of size 194x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.d_ner]:('[torch.LongTensor of size 194x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.q_words]:('[torch.LongTensor of size 10x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.q_pos]:('[torch.LongTensor of size 10x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.c_words]:('[torch.LongTensor of size 6x5]', '[torch.LongTensor of size 5]')\n",
      "\t[.label]:[torch.LongTensor of size 5]\n",
      "\t[.tf]:('[torch.LongTensor of size 194x5]', '[torch.LongTensor of size 5]')\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-461603a789fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch)\n",
    "#     print(batch.tf)\n",
    "    raise Exception()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(TEXT.vocab), embed_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "embedding.weight.requires_grad=False\n",
    "embedding = embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "refer to\n",
    "\n",
    "https://github.com/intfloat/commonsense-rc\n",
    "\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "\n",
    "https://discuss.pytorch.org/t/solved-multiple-packedsequence-input-ordering/2106/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, rnn_output_dropout_rate):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.rnn_output_dropout = nn.Dropout(rnn_output_dropout_rate)\n",
    "    \n",
    "    def forward(self, inputs, lengths):\n",
    "        \"\"\"\n",
    "        take inputs (embedded and padded), return outputs from lstm\n",
    "        \n",
    "        :param inputs: (batch_size, seq_len, embed_dim)\n",
    "        :param lengths: (batch_size)\n",
    "        :return: (batch_size, seq_len, hidden_size * 2)\n",
    "        \"\"\"\n",
    "        lengths_sorted, sorted_idx = lengths.sort(descending=True)\n",
    "        inputs_sorted = inputs[sorted_idx]\n",
    "    \n",
    "        inputs_packed = nn.utils.rnn.pack_padded_sequence(inputs_sorted, lengths_sorted.tolist(), batch_first=True)\n",
    "        outputs_packed, _ = self.lstm(inputs_packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs_packed, batch_first=True)\n",
    "        \n",
    "        # Reverses sorting. \n",
    "        outputs = torch.zeros_like(outputs)\\\n",
    "            .scatter_(0, sorted_idx.unsqueeze(1).unsqueeze(1)\n",
    "                      .expand(-1, outputs.shape[1], outputs.shape[2]), outputs)\n",
    "        outputs = self.rnn_output_dropout(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengths_to_mask(lengths, dtype=torch.uint8):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param lengths: (batch_size)\n",
    "    :param dtype: \n",
    "    :return: (batch_size, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    lengths = lengths.cpu()\n",
    "    \n",
    "    max_len = lengths.max().item()\n",
    "    mask = torch.arange(max_len,\n",
    "                        dtype=lengths.dtype).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "\n",
    "    mask = torch.as_tensor(mask, dtype=dtype, device=device)\n",
    "    mask = 1 - mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqAttnContext(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(SeqAttnContext, self).__init__()\n",
    "        \n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x, y, y_mask):\n",
    "        \"\"\"\n",
    "        calculate context vectors for x on y using attention on y\n",
    "        \n",
    "        :param x: (batch_size, x_seq_len, embed_dim)\n",
    "        :param y: (batch_size, y_seq_len, embed_dim)\n",
    "        :param y_lengths: (batch_size)\n",
    "        :return: (batch_size, x_seq_len, embed_dim)\n",
    "        \"\"\"\n",
    "        x_proj = self.proj(x)\n",
    "        y_proj = self.proj(y)\n",
    "        \n",
    "        scores = x_proj.bmm(y_proj.transpose(2, 1))\n",
    "        \n",
    "        # mask scores\n",
    "        y_mask = y_mask.unsqueeze(1).expand(scores.size())\n",
    "        \n",
    "        scores.data.masked_fill_(y_mask.data, -float('inf'))\n",
    "        weights = self.softmax(scores)\n",
    "        \n",
    "        # Take weighted average\n",
    "        contexts = weights.bmm(y)\n",
    "        # here, instead of using y, maybe use another projection of y in the future\n",
    "        \n",
    "        return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearAttnEncoder(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(BilinearAttnEncoder, self).__init__()\n",
    "        self.linear = nn.Linear(y_dim, x_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x, y, x_mask):\n",
    "        \"\"\"\n",
    "        summarize x into single vectors using bilinear attention on y\n",
    "        \n",
    "        :param x: (batch_size, seq_len, x_dim)\n",
    "        :param y: (batch_size, y_dim)\n",
    "        :param x_mask: (batch_size, seq_len)\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        y_proj = self.linear(y).unsqueeze(2)  # (batch_size, x_dim, 1)\n",
    "        scores = x.bmm(y_proj).squeeze(2)\n",
    "        \n",
    "        scores.data.masked_fill_(x_mask.data, -float('inf'))\n",
    "        weights = self.softmax(scores) # (batch_size, seq_len)\n",
    "        \n",
    "        return weights.unsqueeze(1).bmm(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttnEncoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttnEncoder, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, inputs, mask):\n",
    "        \"\"\"\n",
    "        Summarize inputs into single vectors using self attention\n",
    "        \n",
    "        :param self: \n",
    "        :param inputs: (batch_size, seq_len, input_dim)\n",
    "        :param mask: (batch_size, seq_len)\n",
    "        :return: (batch_size, input_dim)\n",
    "        \"\"\"\n",
    "        scores = self.linear(inputs).squeeze(2)\n",
    "        scores.data.masked_fill_(mask.data, -float('inf'))\n",
    "        weights = self.softmax(scores) # (batch_size, seq_len)\n",
    "        \n",
    "        return weights.unsqueeze(1).bmm(inputs).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilinear(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(Bilinear, self).__init__()\n",
    "        self.linear = nn.Linear(x_dim, y_dim)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        Calculate the biliear function x*W*y\n",
    "        \n",
    "        :param x: (batch_size, x_dim)\n",
    "        :param y: (batch_size, y_dim)\n",
    "        :return: (batch_size)\n",
    "        \"\"\"\n",
    "        xW = self.linear(x)  # (batch_size, y_dim)\n",
    "        return xW.unsqueeze(1).bmm(y.unsqueeze(2)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriAn(nn.Module):\n",
    "    def __init__(self, embedding):\n",
    "        super(TriAn, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.d_rnn = BLSTM(embed_dim * 2, hidden_size, num_layers, rnn_dropout_rate)\n",
    "        self.q_rnn = BLSTM(embed_dim, hidden_size, num_layers, rnn_dropout_rate)\n",
    "        self.c_rnn = BLSTM(embed_dim * 3, hidden_size, num_layers, rnn_dropout_rate)\n",
    "        \n",
    "        self.embed_dropout = nn.Dropout(embed_dropout_rate)\n",
    "        \n",
    "        self.d_on_q_attn = SeqAttnContext(embed_dim)\n",
    "        self.c_on_q_attn = SeqAttnContext(embed_dim)\n",
    "        self.c_on_d_attn = SeqAttnContext(embed_dim)\n",
    "        \n",
    "        self.d_on_q_encode = BilinearAttnEncoder(hidden_size * 2, hidden_size * 2)\n",
    "        self.q_encode = SelfAttnEncoder(hidden_size * 2)\n",
    "        self.c_encode = SelfAttnEncoder(hidden_size * 2)\n",
    "        \n",
    "        self.d_c_bilinear = Bilinear(hidden_size * 2, hidden_size * 2)\n",
    "        self.q_c_bilinear = Bilinear(hidden_size * 2, hidden_size * 2)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, d_words, d_lengths, q_words, q_lengths, c_words, c_lengths):\n",
    "        # embed inputs\n",
    "        d_embed, q_embed, c_embed = self.embedding(d_words), \\\n",
    "            self.embedding(q_words), self.embedding(c_words)\n",
    "        d_embed, q_embed, c_embed = self.embed_dropout(d_embed), self.embed_dropout(q_embed),\\\n",
    "            self.embed_dropout(c_embed)\n",
    "        \n",
    "        # get masks\n",
    "        d_mask = lengths_to_mask(d_lengths)\n",
    "        q_mask = lengths_to_mask(q_lengths)\n",
    "        c_mask = lengths_to_mask(c_lengths)\n",
    "        \n",
    "        # get attention contexts\n",
    "        d_on_q_contexts = self.embed_dropout(self.d_on_q_attn(d_embed, q_embed, q_mask))\n",
    "        c_on_q_contexts = self.embed_dropout(self.c_on_q_attn(c_embed, q_embed, q_mask))\n",
    "        c_on_d_contexts = self.embed_dropout(self.c_on_d_attn(c_embed, d_embed, d_mask))\n",
    "        \n",
    "        # form final inputs for rnns\n",
    "        d_rnn_inputs = torch.cat([d_embed, d_on_q_contexts], dim=2)\n",
    "        q_rnn_inputs = torch.cat([q_embed], dim=2)\n",
    "        c_rnn_inputs = torch.cat([c_embed, c_on_q_contexts, c_on_d_contexts], dim=2)\n",
    "        \n",
    "        # calculate rnn outputs\n",
    "        d_rnn_outputs = self.d_rnn(d_rnn_inputs, d_lengths)\n",
    "        q_rnn_outputs = self.q_rnn(q_rnn_inputs, q_lengths)\n",
    "        c_rnn_outputs = self.c_rnn(c_rnn_inputs, c_lengths)        \n",
    "        \n",
    "        # get final representations\n",
    "        q_rep = self.q_encode(q_rnn_outputs, q_mask)\n",
    "        c_rep = self.c_encode(c_rnn_outputs, c_mask)\n",
    "        d_rep = self.d_on_q_encode(d_rnn_outputs, q_rep, d_mask)\n",
    "        \n",
    "        dWc = self.d_c_bilinear(d_rep, c_rep)\n",
    "        qWc = self.q_c_bilinear(q_rep, c_rep)\n",
    "        \n",
    "        logits = dWc + qWc\n",
    "        return self.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TriAn(embedding).to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr, weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,15], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuaracy(outputs, labels):\n",
    "    preds = (outputs > 0.5).float()\n",
    "    acc = torch.mean((preds==labels).float())\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_batch(batch):\n",
    "    d_words, d_lengths = batch.d_words\n",
    "    q_words, q_lengths = batch.q_words\n",
    "    c_words, c_lengths = batch.c_words\n",
    "\n",
    "    d_words, d_lengths = torch.transpose(d_words, 0, 1), d_lengths\n",
    "    q_words, q_lengths = torch.transpose(q_words, 0, 1), q_lengths\n",
    "    c_words, c_lengths = torch.transpose(c_words, 0, 1), c_lengths\n",
    "\n",
    "    labels = batch.label.float()\n",
    "    \n",
    "    return d_words, d_lengths, q_words, q_lengths, c_words, c_lengths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    scheduler.step()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_accus = []\n",
    "    \n",
    "    for i, batch in enumerate(train_iter):\n",
    "        # get batch\n",
    "        d_words, d_lengths, q_words, q_lengths, \\\n",
    "            c_words, c_lengths, labels = parse_batch(batch)\n",
    "        \n",
    "        # get outputs and loss\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(d_words, d_lengths, q_words, q_lengths, c_words, c_lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # update model\n",
    "        loss.to(device)\n",
    "        loss.backward()\n",
    "        \n",
    "        _ = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clipping)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # record losses and accuracies\n",
    "        epoch_losses.append(loss.item())\n",
    "        accu = get_accuaracy(outputs, labels)\n",
    "        epoch_accus.append(accu.item())\n",
    "#         break\n",
    "    \n",
    "    accu_avg = np.mean(np.array(epoch_accus))\n",
    "    loss_avg = np.mean(np.array(epoch_losses))\n",
    "    \n",
    "    return accu_avg, loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch():\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_accus = []\n",
    "    \n",
    "    for i, batch in enumerate(val_iter):\n",
    "        # get batch\n",
    "        d_words, d_lengths, q_words, q_lengths, \\\n",
    "            c_words, c_lengths, labels = parse_batch(batch)\n",
    "        \n",
    "        # eval\n",
    "        with torch.no_grad():\n",
    "            outputs = model(d_words, d_lengths, q_words, q_lengths, c_words, c_lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # record losses and accuracies\n",
    "            epoch_losses.append(loss.item())\n",
    "            accu = get_accuaracy(outputs, labels)\n",
    "            epoch_accus.append(accu.item())\n",
    "#             break\n",
    "    \n",
    "    accu_avg = np.mean(np.array(epoch_accus))\n",
    "    loss_avg = np.mean(np.array(epoch_losses))\n",
    "    \n",
    "    return accu_avg, loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epoch):\n",
    "    print('~' * 80)\n",
    "        \n",
    "    cur_lr = optimizer.param_groups[0]['lr']\n",
    "    start = time.time()\n",
    "    \n",
    "    train_accu, train_loss = train_epoch()\n",
    "    eval_accu, eval_loss = eval_epoch()\n",
    "    \n",
    "    end = time.time()\n",
    "    print('%dth iteration took %.4f' % (epoch, end - start))\n",
    "    print('learning rate: %.4f' % cur_lr)\n",
    "    print('train_loss: %.4f' % train_loss)\n",
    "    print('eval_loss: %.4f' % eval_loss)\n",
    "    print('train_accuracy: %.4f' % train_accu)\n",
    "    print('eval_accuracy: %.4f' % eval_accu)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
