{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 5\n",
    "batch_size_eval = 256\n",
    "emb_dim = 50\n",
    "embed_from = \"glove.6B.50d\"\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "rnn_dropout = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "refer to \n",
    "\n",
    "http://anie.me/On-Torchtext/\n",
    "\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "\n",
    "http://mlexplained.com/2018/02/15/language-modeling-tutorial-in-torchtext-practical-torchtext-part-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'preprocessed'\n",
    "combined_fname = 'all-combined-data-processed.json'\n",
    "train_fname = 'train-trial-combined-data-processed.json'\n",
    "dev_fname = 'dev-data-processed.json'\n",
    "test_fname = 'test-data-processed.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have keys: 'id', 'd_words', 'd_pos', 'd_ner', 'q_words', 'q_pos', 'c_words', 'label', 'in_q', 'in_c', 'lemma_in_q', 'tf', 'p_q_relation', 'p_c_relation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 20482, val: 2822, test: 5594\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.ReversibleField(sequential=True, lower=True, include_lengths=True)\n",
    "\n",
    "train, val, test = data.TabularDataset.splits(\n",
    "    path=data_dir, train=train_fname,\n",
    "    validation=dev_fname, test=test_fname, format='json',\n",
    "    fields={'d_words': ('d_words', TEXT),\n",
    "            'q_words': ('q_words', TEXT),\n",
    "            'c_words': ('c_words', TEXT),\n",
    "            'label': ('label', data.Field(sequential=False, use_vocab=False))\n",
    "           })\n",
    "\n",
    "print('train: %d, val: %d, test: %d' % (len(train), len(val), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 10695\n"
     ]
    }
   ],
   "source": [
    "# combined is only used for building vocabulary\n",
    "combined = data.TabularDataset(\n",
    "    path=os.path.join(data_dir, combined_fname), format='json',\n",
    "    fields={'d_words': ('d_words', TEXT),\n",
    "            'q_words': ('q_words', TEXT),\n",
    "            'c_words': ('c_words', TEXT),\n",
    "            'label': ('label', data.Field(sequential=False, use_vocab=False))\n",
    "           })\n",
    "\n",
    "# TEXT.build_vocab(combined)\n",
    "TEXT.build_vocab(combined, vectors=embed_from)\n",
    "print('vocab size: %d' % len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter, val_iter, test_iter = data.Iterator.splits(\n",
    "#         (train, val, test), sort_key=lambda x: len(x.d_words), \n",
    "#         batch_sizes=(batch_size_train, batch_size_eval, batch_size_eval), device=-1, \n",
    "#         sort_within_batch=True, repeat=False)\n",
    "\n",
    "train_iter, val_iter, test_iter = data.Iterator.splits(\n",
    "        (train, val, test), batch_sizes=(batch_size_train, batch_size_eval, batch_size_eval), device=device, \n",
    "        sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
       "        ...,\n",
       "        [-0.1160,  1.1429,  0.0260,  ..., -0.8676,  0.0750,  0.8040],\n",
       "        [-0.5689,  0.9256,  0.7289,  ...,  0.7101, -0.2287,  1.4826],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10695, 50])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model\n",
    "refer to\n",
    "\n",
    "https://github.com/intfloat/commonsense-rc\n",
    "\n",
    "https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e\n",
    "\n",
    "https://discuss.pytorch.org/t/solved-multiple-packedsequence-input-ordering/2106/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, rnn_dropout):\n",
    "        super(VLBLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=rnn_dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "    \n",
    "    def forward(self, inputs, lengths):\n",
    "        # requires inputs to be batch first\n",
    "        lengths_sorted, sorted_idx = lengths.sort(descending=True)\n",
    "        inputs_sorted = inputs[sorted_idx]\n",
    "    \n",
    "        inputs_packed = nn.utils.rnn.pack_padded_sequence(inputs_sorted, lengths_sorted.tolist(), batch_first=True)\n",
    "        outputs_packed, _ = self.lstm(inputs_packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs_packed, batch_first=True)\n",
    "        \n",
    "        # Reverses sorting. \n",
    "        outputs = torch.zeros_like(outputs)\\\n",
    "            .scatter_(0, sorted_idx.unsqueeze(1).unsqueeze(1)\n",
    "                      .expand(-1, outputs.shape[1], outputs.shape[2]), outputs)\n",
    "        \n",
    "        return outputs\n",
    "        \n",
    "\n",
    "# class TriAN(nn.Module):\n",
    "#     def __init__(self, embedding):\n",
    "#         super(TriAN, self).__init__()\n",
    "#         self.embedding = embedding\n",
    "#         self.doc_rnn = ???\n",
    "#         self.question_rnn = ???\n",
    "#         self.choice_rnn = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BLSTM(emb_dim, hidden_size, num_layers, rnn_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([198, 214, 188, 177, 175])\n",
      "tensor([[[-0.1746,  0.0269,  0.2662,  ..., -0.0008, -0.0549,  0.1810],\n",
      "         [-0.1200,  0.0884,  0.2625,  ..., -0.0027, -0.0642,  0.0378],\n",
      "         [-0.1149,  0.1104,  0.2383,  ...,  0.1011,  0.0217,  0.0867],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1444,  0.0177,  0.1477,  ...,  0.0404, -0.0392,  0.1008],\n",
      "         [-0.1623, -0.0442,  0.0949,  ..., -0.0021, -0.0375,  0.0130],\n",
      "         [-0.1534,  0.0477,  0.1611,  ...,  0.0179, -0.0453,  0.1759],\n",
      "         ...,\n",
      "         [-0.1052,  0.0392,  0.2023,  ...,  0.0442, -0.0547,  0.0747],\n",
      "         [-0.0661,  0.0552,  0.1639,  ...,  0.0710, -0.0368,  0.0608],\n",
      "         [-0.0796,  0.0906,  0.1743,  ...,  0.0706, -0.0201,  0.0445]],\n",
      "\n",
      "        [[-0.1304,  0.1922,  0.2095,  ...,  0.1259, -0.0899,  0.2511],\n",
      "         [-0.1760,  0.2351,  0.2446,  ...,  0.0945, -0.0689,  0.2660],\n",
      "         [-0.1697,  0.1544,  0.2125,  ...,  0.0921, -0.1079,  0.2176],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0874,  0.0453,  0.2289,  ..., -0.0282, -0.0313,  0.1093],\n",
      "         [-0.0954, -0.0509,  0.1278,  ..., -0.0952,  0.0018,  0.1062],\n",
      "         [-0.1176, -0.1099,  0.0995,  ...,  0.0101, -0.0497,  0.1219],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0779,  0.0456, -0.0088,  ..., -0.0306, -0.0352,  0.1552],\n",
      "         [-0.1182,  0.0791,  0.1219,  ...,  0.0118, -0.0127,  0.1870],\n",
      "         [-0.1140,  0.0538,  0.0373,  ..., -0.0112,  0.0237,  0.2110],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_iter):\n",
    "    d_words, d_lengths = batch.d_words\n",
    "    q_words, q_lengths = batch.q_words\n",
    "    c_words, c_lengths = batch.c_words\n",
    "    labels = batch.label\n",
    "    \n",
    "    # convert to batch first\n",
    "    d_words = torch.transpose(d_words, 0, 1)\n",
    "    q_words = torch.transpose(q_words, 0, 1)\n",
    "    c_words = torch.transpose(c_words, 0, 1)\n",
    "    \n",
    "    d_words_embed = embedding(d_words)\n",
    "    outputs = rnn(d_words_embed, d_lengths)\n",
    "    \n",
    "#     print(d_words.shape, d_lengths.shape, labels.shape)\n",
    "#     print(d_lengths)\n",
    "#     print(q_lengths)\n",
    "#     print(c_lengths)\n",
    "\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
